Molecular analyses of bat guano content enables researchers to test a suite of ecological and evolutionary hypotheses. From simply listing observed taxa, to hypothesis testing of foraging behaviors (Vesterinen et al. 2016) or niche partitioning (Vesterinen et al. 2018), to modeling complex spatiotemporal dynamics of food webs (Clare et al. 2014), each analysis is made possible because of the pairing of high throughput sequencing with metabarcoding fecal content. The inherent flexibility of modern sequencing has expanded the number of users and studies, yet this same permissiveness lends itself to distinct molecular and bioinformatic parameters being employed between experiments. The factors considered among every amplicon analysis are extensive: sample collection, primer and barcode design, sequencing platform, as well as sequence data processing and taxonomic assignment are among the questions to be considered in each experiment (reviewed extensively by (Pompanon et al. 2012, Clare 2014, and especially well illustrated and evaluated by (Alberdi et al. 2018)). Despite the complexity and diversity of considerations relating to generating the sequence data, the guidance for the past decade was relatively straightforward for arthropod diet analyses: sample as exhaustively as budget and time allow, choose primers that appear to amplify the select taxa with as little bias as possible, and sequence with the most accurate platform available. The analytical objectives of these experiments were also restricted in scope: the resulting counts of unique amplicon sequence variants (ASV) were traditionally transformed into a binary presence/absence (PA) formats for most downstream analyses such as alpha and beta diversity measures. However, this apparent coalescence of methodology belies the capacity to faithfully compare results between experiments when bioinformatic processes differ.

Commentary on best practices are frequently derived from mock community samples - a practice that is extensive and commonplace in microbial gene marker research, but not among arthropod datasets. Connecting wet-bench experimental design to systematic error and biases of observed sequence data (Gohl et al. 2016), optimizing filtering parameters (Bokulich et al. 2013), understanding tradeoffs among sequence error correction (Nearing et al. 2018), and evaluating taxonomic classification regimes (Bokulich et al. 2018) are each made possible because of predefined collections of samples with expected sequence identity and abundance. Systematic evaluation of arthropod studies are growing but far more limited in scope: synthetic mock samples have been used to explore the potential for alternative primer use (Beng et al. 2016), while biological mock samples have been used to improve quality filtering of spurious sequence variants (Jusino et al. 2019) as well as to evaluate the utility of PCR replicates (Galan et al. 2018). In addition, a few studies have used real data to offer insights into a the effects of sequencing platforms (Divoll et al. 2018) as well as on a single filtering parameter (clustering radius) (Alberdi et al. 2018) though this was specific to just a single program. We sought to build upon these evaluations by using both real and biological mock data to illustrate how certain bioinformatic decisions skew the resulting interpretations of some of the most common goals of bat diet analyses - observed richness and community composition within and between samples. Such decision criteria are grouped into three broad categories: representative sequence selection and filtering (sequence filtering), reference sequence selection and filtering (database curation), and representative sequence classification (assigning taxonomy).

As with microbial systems, experimental design among arthropod diet studies vary with some researchers using relatively more dated methods than others. For example, one of the first considerations in an amplicon study is whether to to correct unique sequence by generating error models to detect and act upon potential sequence errors (often referred to as ‘denoising’) or to group sequence variants at some user-defined similarity. These have been explored empirically in a microbial setting (Glassman and Martiny 2018); while the observed differences were small in that single study, practical reasons such as database independence and the potential to preserve sequence diversity point to ASVs as being superior to OTU-based classification (Callahan et al. 2017). Yet even among recently published bat diet studies it is often the case that fewer experiments adopt the newer denoising approaches (Vesterinen et al. 2018) and instead favor a clustering method (Kaunisto et al. 2017; Czenze et al. 2018; Bohmann et al. 2018; Divoll et al. 2018); we use mock communities to evaluate the consequences of this decision.

Classification is another broadly inconsistent bioinformatic step among bat diet studies, both in terms of how a representative sequence variant is assigned taxonomy as well as how a database was constructed to query sequences for assignment. With respect to reference databases nearly all bat diet publications rely on some combination of Genbank (Benson et al. 2005) and the Barcode of Life Database (Ratnasingham and Hebert 2007) (BOLD). Some customization is often performed through programs like bold-retriever (Vesterinen et al. 2016) or R-bold (Chamberlain 2017) that access the repositories and allow users to filter for select metadata.  In addition, varying methods to classify a unique sequence variant exist: some prefer employing boundaries with fixed identity thresholds to define certain taxonomic levels (Vesterinen et al. 2016; Clare et al. 2009; Razgour et al. 2011); others use a least common ancestor approach when multiple best hits are available (Galan et al. 2018). There are two problems that become intertwined with respect to how sequences are classified: unlike microbial reference databases like Greengenes (DeSantis et al. 2006) and SILVA (Pruesse et al. 2007), arthropod studies generate databases on an ad hoc basis, and even among studies performed at similar times the selective retention or expulsion of certain references makes it challenging to understand if differences observed between studies is a product of meaningful biology or ephemeral database curation.

A few arthropod diet studies have started to explore the utility of using relative abundances (RA) of sequence counts instead of the classic PA design (reviewed by (Deagle et al. 2018)). While mock communities fail to replicate the true complexity observed in actual diet samples, mock samples are essential at providing a ground truth when evaluating bioinformatic processes like filtering parameters; for example, such tests highlight the degree with which low abundance sequence artifacts are generated in a pipeline-dependent manner. We sought to understand how our interpretations of apparent diversity within and between samples is influenced by such count transformations, and how the count data itself is influenced by the choice of filtering program used. In addition, we demonstrate how distinct classification strategies can lead to further differentiating the interpretation of diversity in a dataset. We selected four libraries of cytochrome c oxidase subunit 1 (COI) data generated from an ongoing bat diet study which included hundreds of bat guano samples in addition to a biological mock community sample included in each sequencing run. Libraries were processed with one of three filtering programs: vsearch (Rognes et al. 2016) represents a clustering approach, while dada2 (Callahan et al. 2016) and deblur (Amir et al. 2017) were represent denoising programs. We perform each of these analyses within a QIIME2 framework (Bolyen et al. 2018) to advocate for an increased use of open source tools within the bat community. Data and documentation for all bioinformatic steps are hosted on Github (www.github.com/devonorourke/tidybug).


Results
See bottom of document for figures and tables referred to herein.



Methods
Mock samples
Mock community samples were provided by Michelle Jusino and Dan Lindner, and constructed as described by Jusino (2019). In brief, these samples consisted of DNA extracted from voucher arthropod specimen that was amplified using their novel ANML primers; PCR products were cloned into plasmid vectors and Sanger sequenced. This mock community consists of 24 representative COI sequences derived from 23 taxa; one of the taxa (Harmonia axyridis) generated two distinct COI amplicons. The mock community used in this project consists of equimolar concentrations of plasmids, not post-plasmid PCR product. Taxa identities were assigned by entomologist visual confirmation and confirmed by manually aligning sequences to NCBI nt database. Sequence and taxa identities are provided in the ‘CFMR_insect_mock4_wtax.fasta file’ at the Github repo for this project (github.com/devonorourke/tidybug). A single tube containing the mock community sample was used to generate COI amplicons using techniques described below.

Site selection and sample collection
Guano was sampled passively by both researchers and citizen scientists as part of a broader collection effort spanning two years throughout multiples sites in the United States including New Hampshire, Massachusetts, Vermont, Maine, Indiana, Kentucky, and Virginia. However, the vast majority of guano samples selected for this report (1,675 of 1,790) were collected in sites specific to New Hampshire. Prospective sites were identified through previous partnerships and participation in summer counts at the volunteers sites. Collection materials were provided and shipped to each volunteer as a kit and included alcohol wipes, forceps, 0.31 mil plastic sheets, collection boxes, and collection tubes filled with 1 mL storage buffer (3.5M ammonium sulfate, 16.7 mM sodium citrate, 13.3 mM EDTA, pH 5.2). Volunteers were provided with instructions to lay a sheet of plastic beneath the location with the greatest amount of fresh droppings; sampling started within the first 6 days, with up to 10 individual pellets being collected (ie. one collection tube per pellet). A new sheet of plastic was used each week, and volunteers were instructed to clean forceps between each week of sampling. Samples were shipped back to our lab and stored at -80 °C until DNA extraction commenced.

Laboratory work
Guano samples were thawed and transferred to individual wells of a 96-well plate provided by the Qiagen DNEasy PowerSoil Kit (Cat No. 12955-4, Qiagen, Hilden, Germany). DNA was extracted following manufacturer guidelines. Extraction blanks were included for each plate.
We used a dual indexed primer pair inspired by the template from Kozich, Westcott, Baxter, Highlander, and Schloss (2013). This design incorporates both the necessary generic elements of Illumina adapters while allowing for customized barcodes and COI-targeted primer sequence. The COI primer design matches that previously described by Jusino et al. (2019), resulting in primer pairs (ANMLxf:5’-AATGATACGGCGACCACCGAGATCTACAC<i5>TATGGTAATTCGGGTCAACAAATCATAAAGATATTGG-3’) and (ANMLxr:5’-CAAGCAGAAGACGGCATACGAGAT<i7>AGTCAGTCAGCCGGWACTAATCAATTTCCAAATCC-3’), where i5 and i7 represent a unique 8bp barcode. Lists for all possible primer pairs with barcodes are listed in the metadata directory of the Github repo for this project (https://github.com/devonorourke/tidybug/blob/master/data/metadata/primerpairs.txt). 25 uL reactions were constructed by adding 10 uL of extracted DNA with 1 uL each of 10 mM forward and reverse primer pairs with 13 uL of AccuStart II PCR SuperMix (Cat No. 95137-04K, Quanta BioSciences, Gaithersburgh, MD, USA). Mock community samples were amplified using a distinct primer pair that was not used on any guano samples for any libraries in any study; further, mock samples were amplified in a separate reaction from guano samples to avoid any potential cross contamination. For the mock samples, 1 uL of template DNA with 9 uL of nuclease free water was used in lieu of 10 uL of guano extract. Reaction conditions consisted of: an initial denaturation step at 95 °C for 2 minutes; 30 cycles of denaturation at 95 °C for 20 seconds, annealing at 50 °C for 15 seconds, and extension at 72 °C for 60 seconds; a final extension at 72 °C for 10 minutes. PCR products were quantified using a PicoGreen assay (Cat No. P7589, Invitrogen, Carlsbad, CA, USA) and Tecan plate reader with excitation and emission wavelengths of 480 nm and 520 nm, respectively (Tecan Group Ltd., Männedorf, Switzerland). Samples were pooled in approximately equimolar ratios; because there were hundreds of samples pooled in a single library, the exact expected equimolar volumes were rounded to the nearest bin (bin sizes set at 0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10, 15, or 20 uL). Extraction blanks or guano samples with detectable DNA that required exceeding the maximum pool bin volume were included at a fixed volume of 20 uL. The initial pool volume was reduced with a vacuum concentrator to approximately 2 mL, and cleaned with a QIAquick PCR purification kit (Cat No. 28104, Qiagen, Hilden, Germany); libraries were eluted in 30 uL EB buffer. Libraries were quantified by Qubit High Sensitivity assay (Cat No. Q32854) and fragment sizes analyzed using TapeStation D1000 ScreenTape (Agilent Technologies, Santa Clara, CA, USA). Libraries were submitted to Northern Arizona University and sequenced using an Illumina MiSeq platform (Illumina Inc., San Diego, CA, USA) using v3 chemistry with 600 cycles of 2x300 bp paired-end read lengths.

Bioinformatics
Complete bioinformatic details are described at the Github repo (github.com/devonorourke/tidybug); in particular, the `tidybug/docs/sequence_filtering.md` document details trimming raw sequence data with Cutadapt (Martin 2011), then processing the unpaired reads with one of three filtering pipelines using either Vsearch (Rognes et al. 2016), DADA2 (Callahan et al. 2016), or Deblur (Amir et al. 2017). All of these processes were completed within a QIIME2 environment (Bolyen et al. 2018). Briefly, these processes consist of importing the fastq files into the QIIME ‘.qza’ artifact file format, primer trimming, and either denoising or clustering the paired-end reads on a per-library basis; we chose to process data on individual libraries rather than concatenating all data together because denoising programs build error models on either a per-sample or per-library basis. The resulting representative sequences had bat-associated COI sequences removed and representative sequence (fasta-like) files and frequency tables of sequence counts (OTU table-like) were merged for all libraries. Frequency tables served as input for diversity analyses.
Mock community samples were processed as part of the overall library; we expect that the per-sample error rate is similar for mock and guano samples. Mock sequence information was subset from the larger library following the filtering processes described above and aligned to the expected representative sequences to determine what ASVs were exact matches (100% identity), partial matches (97 - 99.9% identity), or misses (< 97% identity).

add further commentary summarizing work for database curation workflow...
Additional documentation in the `tidybug/docs` directory highlights the additional scripts used for diversity metric calculations, as well as all scripts used to for database curation analyses.




Figure 1: The proportion of filtered sequences varies by program. Deblur consistently retains fewer sequences per library than dada2 or vsearch. Four libraries sequenced (libA to libD) on independent MiSeq runs.




Figure 2:
Denoising programs produce distinct profiles relative to clustering program. Exact matches reflect 100% identity between ASV detected in mock community and a known mock sequence, partial match reflects between 97-99.9% identity, and miss represents an ASV with less than 97% identity to known mock sequences. Vsearch consistently produces vastly more misses and partial matches, while denoising programs dada2 and deblur have few false positive detections.


Table 1:
Summary of per-Library or per-Pipeline overlaps in shared ASVs. Shared ASVs within a library (orange, left to right) reflect those sequences common across all filtering pipelines. Shared ASVs within a pipeline (blue, top to bottom) reflect sequences common across all mock community samples/libraries. Among Exact matches (ASVs with 100% identity to expected mock sequences) denoising algorithm identifies 22 of 24 expected sequences, while clustering approach identifies fewer, whether or not basic filtering is performed (basic filtering requires a sample to have > 5000 reads, and an OTU to be present in > 1 sample). The remaining 2 expected ASV sequences are detected as Partial matches in every sequencing pipeline, regardless of filtering strategy. Miss ASVs (those detected in mock samples with < 97% identity to known sequences) are much more abundant in a clustering approach than in either denoising program; among denoising Miss ASVs, no sequence occurs in multiple libraries, suggesting these ASVs are a sequencing artifact and not a product of wet-bench contamination.





Figure Supplementary-1:
Any ASV assigned as Miss within either denoise programs (dada2 and deblur) highlighted, colored for each library. Frequency of detection represents the number of samples within a library with that particular Miss ASV. While the mean and median number of samples with any one ASV is between 2 to 8 per Library, many of the Miss ASVs observed in the mock samples occur in > 50 samples suggesting index-bleed as a probable source with which these low-frequency false positives are generated.



