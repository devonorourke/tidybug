Introduction
Molecular analyses of bat guano content enables researchers to test a suite of ecological and evolutionary hypotheses. From simply listing observed taxa, to hypothesis testing of foraging behaviors (Vesterinen et al. 2016) or niche partitioning (Vesterinen et al. 2018), to modeling complex spatiotemporal dynamics of food webs (Clare et al. 2014), each analysis is made possible because of the pairing of high throughput sequencing with metabarcoding fecal content. The inherent flexibility of modern sequencing has expanded the number of users and studies, yet this same permissiveness lends itself to distinct molecular and bioinformatic parameters being employed between experiments. The factors considered among every amplicon analysis are extensive: sample collection, primer and barcode design, sequencing platform, as well as sequence data processing and taxonomic assignment are among the questions to be considered in each experiment (reviewed extensively by (Pompanon et al. 2012, Clare 2014, and especially well described by (Alberdi et al. 2018)). Despite the complexity and diversity of considerations relating to generating the sequence data, the guidance for the past decade was relatively straightforward for arthropod diet analyses: sample as exhaustively as budget and time allow, choose primers that appear to amplify the select taxa with as little bias as possible, and sequence with the most accurate platform available. The analytical objectives of these experiments were also restricted in scope: the resulting counts of unique amplicon sequence variants (ASV) were traditionally transformed into a binary presence/absence (PA) formats for most downstream analyses such as alpha and beta diversity measures. However, this apparent coalescence of methodology belies the capacity to faithfully compare results between experiments when bioinformatic processes differ.

Commentary on best practices are frequently derived from mock community samples - a practice that is extensive and commonplace in microbial gene marker research, but not among arthropod datasets. Connecting wet-bench experimental design to systematic error and biases of observed sequence data (Gohl et al. 2016), optimizing filtering parameters (Bokulich et al. 2013), understanding tradeoffs among sequence error correction (Nearing et al. 2018), and evaluating taxonomic classification regimes (Bokulich et al. 2018) are each made possible because of predefined collections of samples with expected sequence identity and abundance. Systematic evaluation of arthropod studies are growing but far more limited in scope relative to microbial experiments: synthetic mock samples have been used to explore the potential for alternative primer use (Beng et al. 2016), while biological mock samples have been used to improve quality filtering of spurious sequence variants (Jusino et al. 2019) as well as to evaluate the utility of PCR replicates (Galan et al. 2018). In addition, a few studies have used real data to offer insights into a the effects of sequencing platforms (Divoll et al. 2018) as well as on a single filtering parameter (clustering radius) (Alberdi et al. 2018) though this was specific to just a single program. We sought to build upon these evaluations by using both real and biological mock data to illustrate how certain bioinformatic decisions skew the resulting interpretations of some of the most common goals of bat diet analyses - observed richness and community composition within and between samples. Such decision criteria are grouped into three broad categories: representative sequence selection and filtering (sequence filtering), reference sequence selection and filtering (database curation), and representative sequence classification (assigning taxonomy).

As with microbial systems, experimental design among arthropod diet studies vary with some researchers using relatively more dated methods than others. For example, one of the first considerations in an amplicon study is whether to to correct unique sequence by generating error models to detect and act upon potential sequence errors (often referred to as ‘denoising’) or to group sequence variants at some user-defined similarity. These have been explored empirically in a microbial setting (Glassman and Martiny 2018); while the observed differences were small in that single study, practical reasons such as database independence and the potential to preserve sequence diversity point to ASVs as being superior to OTU-based classification (Callahan et al. 2017). Yet even among recently published bat diet studies it is often the case that fewer experiments adopt the newer denoising approaches (for example, see Vesterinen et al. (2018)) and instead favor a clustering method (for examples see: Kaunisto et al. (2017); Czenze et al. (2018); Bohmann et al. (2018); and Divoll et al. (2018)). We use mock communities to evaluate the consequences of this decision as well as explore trends with libraries of bat guano samples.

Classification is another broadly inconsistent bioinformatic step among bat diet studies, both in terms of how a representative sequence variant is assigned taxonomy as well as how a database was constructed to query sequences for assignment. With respect to reference databases nearly all bat diet publications rely on some combination of Genbank (Benson et al. 2005) and the Barcode of Life Database (Ratnasingham and Hebert 2007) (BOLD). Some customization is often performed through programs like bold-retriever (Vesterinen et al. 2016) or R-bold (Chamberlain 2017) that access the repositories and allow users to filter for select metadata.  In addition, varying methods to classify a unique sequence variant exist: some prefer employing boundaries with fixed identity thresholds to define certain taxonomic levels (Vesterinen et al. 2016; Clare et al. 2009; Razgour et al. 2011); others use a least common ancestor approach when multiple best hits are available (Galan et al. 2018). There are two problems that become intertwined with respect to how sequences are classified: unlike microbial reference databases like Greengenes (DeSantis et al. 2006) and SILVA (Pruesse et al. 2007), arthropod studies generate databases on an ad hoc basis, and even among studies performed at similar times the selective retention or expulsion of certain references makes it challenging to understand if differences observed between studies is a product of meaningful biology or ephemeral database curation.

A few arthropod diet studies have started to explore the utility of using relative abundances (RA) of sequence counts instead of the classic PA design (reviewed by (Deagle et al. 2018)). While mock communities fail to replicate the true complexity observed in actual diet samples, mock samples are essential at providing a ground truth when evaluating bioinformatic processes like filtering parameters; for example, such tests highlight the degree with which low abundance sequence artifacts are generated in a pipeline-dependent manner. We sought to understand how our interpretations of apparent diversity within and between samples is influenced by such count transformations, and how the count data itself is influenced by the choice of filtering program used. In addition, we demonstrate how distinct classification strategies can lead to further differentiating the interpretation of diversity in a dataset. We selected four libraries of cytochrome c oxidase subunit 1 (COI) data generated from an ongoing bat diet study which included hundreds of bat guano samples in addition to a biological mock community sample included in each sequencing run. Libraries were processed with one of three filtering programs: vsearch (Rognes et al. 2016) represents a clustering approach, while dada2 (Callahan et al. 2016) and deblur (Amir et al. 2017) were represent denoising programs. We perform each of these analyses within a QIIME2 framework (Bolyen et al. 2018) to advocate for an increased use of open source tools within the bat community. Data and documentation for all bioinformatic steps are hosted on Github (www.github.com/devonorourke/tidybug).


Results
1. Sequence filtering and diversity interpretations
Bat guano and mock community COI amplicon sequences were produced from four independent sequencing runs (labeled ‘libA’, ‘libB’, ‘libC’, and ‘libD’). Each library was independently processed with three filtering programs (hereafter termed Filtering Method) using default settings available in a QIIME2 (Bolyen et al. 2018) environment: Vsearch (Rognes et al. 2016) provides a clustering approach, while DADA2 (Callahan et al. 2016), and Deblur (Amir et al. 2017) represented two denoising methods. The resulting abundances of filtered reads varied among libraries with respect to Filtering Method (Figure 1), with Deblur retained fewer filtered reads than DADA2 or Vsearch. Differences in retained filtered reads likely stem from the assumptions that each Filtering Method follow. The OTU clustering approach mirrored the parameters outlined at the Vsearch Wiki (github.com/torognes/vsearch/wiki/VSEARCH-pipeline) that include an initial clustering step (98% identity) prior to chimera filtering followed by an additional clustering step (97% identity of filtered data) prior to dereplicating. The reduction in read depth from the Vsearch Filtering Method results from removing singleton reads prior to chimera filtering and discarding suspected chimeras. While taxonomic information can be lost with this clustering method the number of filtered reads is unaffected. DADA2 and Deblur both attempt to correct for sequencing error, but do so in distinct ways: DADA2 constructs a parameterized error model on a per-library basis from metrics including quality scores and relative abundances; the model is used to correct some fraction of suspected sequencing errors and retain the corrected sequences. Unlike DADA2, Deblur is applied to each sample (rather than all samples in a library) and employs a fixed error model that uses ranked abundances of amplicon variants to identify and remove sequences that exceed a defined error threshold.

Filtering Methods are employed to reduce the number of artifactual sequence variants while retaining meaningful biological variation. Overall read abundances match the assumptions of the Filtering Methods employed, but do not evaluate the performance of the process itself. We evaluated each Filtering Method using an arthropod mock community that contained 24 sequence variants of 10 Insect and Aranea Orders described previously (Jusino et al. 2019); there were 23 taxa represented because one species (Harmonia axyridis) contained two distinct COI fragments. We aligned representative sequences identified in each mock sample to the 24 representative sequences to identify those variants that shared 100% identity to an expected sequenced (termed “exact”), and further binned aligned representative sequences into “partial” matches for those between 99.9 to 97% identity, and “miss” for those less than 97% identity.  Each dataset was subject to additional filtering parameters beyond the defaults used in each Filtering Method (hereafter termed Filtering Parameters). We chose three possible Parameters: ‘basic’ represents the default output of a given Filtering Method; ‘standard’ requires that only samples with at least 5000 filtered reads be included and that all singleton sequence variants are discarded; ‘extra’ includes the ‘standard’ parameters and also subtracts a fixed integer from all observations (per sample, per sequence variant, per library, per Filtering Method). The ‘standard’ parameter was chosen to reflect two common strategies for data filtering (per-sample filtering, and per-sequence variant filtering), while the ‘extra’ parameter was chosen to reflect another commonly discussed (though debatable) strategy of removing a fixed threshold of read abundances; we derived this value directly from our mock community sample by identifying the maximum sequence count among all “miss” variants for a given mock sample; these values ranged from 2 to 23, depending on the library and Filtering Method.

Our arthropod mock communities depict stark differences in observed sequence variants among Filtering Methods using default parameters (Figure 2). Denoising pipelines retain similar numbers of sequence variants despite a 20-30% difference in filtered read abundances, while the clustering approach generates hundreds or thousands of variants in a single mock sample. The majority of the sequence variants detected in the denoising Filtering Methods are the “exact” sequences; in addition, the denoising pipelines detect all 24 expected sequences while the clustering approach failed to detect between 1 to 4 expected mock members among the four sequencing runs. For the denoised datasets, 22 of 24 of these were exact matches, while 2 matches were identified as “partial” alignment for every Filtering Parameter. The “partial” designation more likely indicates an incorrectly assigned reference sequences than sequencing error itself given that these two partial matches were the same sequence across all four sequencing runs, and generated a similar abundance of reads as the “exact” mock sequences. We also compared the number of shared sequence variants across Libraries and  Filter Method to identify the degree with which the “exact”, “partial”, or “miss” sequences were distinct to a run or pipeline (Table S1). While denoising approaches uniformly detected the same “exact” sequences across all libraries and Filtering Parameters, the clustering approach detected 16 of 22 “exact” matches regardless of Filtering Parameter. Among the “basic” Filtering Parameter for “miss” sequence variants, a sequence variant was never detected in multiple libraries, suggesting that these variants are likely due to sequencing error instead of potential web bench contamination. The number of false positives (“partial” or “miss” sequence variants) detected increases with deeper sequencing, with the largest mock sample (“libD”) uniformly containing the most observed sequence variants. However, the proportion of observed sequence variants is far more sensitive among the clustering method than the denoising approach. Our results suggest that either denoising approach does a superior job relative to a clustering method in terms of preserving the number of expected sequences and reducing the number of false positives with default parameters.

Among arthropod diet studies additional filtering parameters are routinely applied. While the motivation is to reduce likely sequence errors, the tradeoff of needlessly discarding meaningful biological information may be of consequence both in generating lists of potential diet items as well as subsequent diversity measures - especially when data is transformed into a presence/absence binary model. Notably, the removal of sequences observed once was applied as a dataset-wide decision: that is, variants were retained if they were observed once per Library provided they were identified in another Library in a separate run. Singleton sequence variant removal operates with the assumption that these are likely more a result of sequencing error than biological variation; we see that with the Vsearch clustering method this single filter dramatically reduces the number of remaining sequences, thought it remains 2-3 fold higher than the equivalent denoised samples. Nevertheless, a fraction of unexpected sequences remain across all samples for each Filtering Method with the “standard” Parameter filters; while these contribute very little to the overall read abundance of the library, they may have a strong influence on any diversity metrics that transform data into a presence/absence model. A final “extra” filter reduces the remaining “miss” sequences for each library leaving only exact and a few partial matches (which upon manual inspection were suggestive of sequencing error of expected sequences). This “extra” step of removing a fixed value of read counts across is observed among many bat diet studies in hopes of reducing the noise of putative low-abundance sequence error, yet such an approach likely reduces the complexity of the sequence variants among samples and can bias those samples with lower overall abundance. Further complicating matters are the distinct default parameters for each denoising pipeline: Deblur, by default in QIIME2, discards any sequence variant with less than 10 samples; DADA2, by default in QIIME2, discards only singletons. Suggestions to apply some fixed value have been previously validated for clustering approaches (Bokulich et al. 2013) but are not necessarily encouraged for denoised data. In fact, removing low frequency sequences may run counter to newer modeling approaches that leverage singleton and low-abundances counts for richness (Willis and Bunge 2015) and other diversity measures (Willis and Martin 2018).

We applied the same filtering regimes to the hundreds of bat guano samples sequenced in each of the four libraries to better understand how these methods perform with greater sequence complexity. One measure of performance is obtained by counting the number of times a given read abundance is detected per sequence variant per sample - it’s the distribution of counts of the resulting OTU table.  Unlike the mock samples which contained a binary distribution (thousands of reads for each expected sequence and typically less than ten reads for unexpected sequences), the distribution of read abundances for guano data heavily favored low abundant reads across all sequencing pipelines (Figure 3). While low abundant sequence variants are common among all libraries across every Filtering Method and Filtering Parameter, the shapes of these distributions suggest that default parameters of denoising pipelines are much less dominated by singleton and doubleton reads compared to the clustering approach. Among the denoising pipelines, the right tails of the distributions differ such that the error-correcting method of DADA2 produces more sequence variants with greater read abundances than the error-discarding method of Deblur. The distributions of sequence variant frequencies appear relatively insensitive to Filtering Parameters for the denoising methods, but reduce the left skew of the Vsearch distribution. The mock community profiles suggest that a clustering approach generated far more false positives, that the majority of these low abundance reads are due to sequencing error, and that more errors are expected with more deeply sequenced libraries. While we can’t ascertain the false positive error rates in guano samples, the distributional shifts among Filtering Method and Pipeline support similar notions of a cluster-based approaching being inflated with sequence error. The Vsearch clustering method is dominated by low abundant variants but the left-modal skewed distribution is altered by our Filtering Parameters that essentially discard the most low abundant frequences. The effect is much less noticeable among the denoising Filtering Methods, though it has a greater effect among the most deeply sequence library (libD). Overall we find that a denoising approach is more likely to produce a longer list of observed sequence variants, but this may not necessarily result in a longer list of classified taxa. We were further interested in determining if these differences were of any consequence on the ultimate goal of a typical diet analysis with respect to diversity.

Bat diet analyses have historically transformed sequence abundances into a presence/absence format; consequently most previous reports of compositional similarity were limited to richness for inter-sample similarity and one of a few indices (ex. Dice-Sorensen or Raup-Crick) for intra-sample analyses. Incidence-based approaches are often justified as a safer choice compared to using relative abundances of sequences due to the challenges of associating counts to biomass, yet as Deagle (2018) points out, “to accept the notion that relative sequence counts provide no meaningful information would mean that, within one sample, a few DNA sequences from one food taxon are equivalent to 10,000 sequences from another”. We used the iNEXT package (Hsieh et al. 2016) to first explore how inter-sample diversity estimates would change among our mock community samples in presence absence and relative abundance frameworks. Accumulation curves estimating observed richness in a presence-absence context for each mock sample suggest that a clustering based approach monotonically increases with sampling depth and fails to plateau without additional Filtering Parameters being imposed (Figure 4). Denoising programs appear less sensitive to sampling depth, with asymptotic estimates of diversity plateauing prior to reaching the actual depth of sample as well as sharing overlapping 95% confidence intervals for both “basic” and “standard” Filtering Parameters. Among our mock samples, all Filtering Methods generated the most sequence variants with the highest throughput, yet the sensitivity with respect to how many more sequences were generated is far greater with a clustering approach unless additional filtering parameters were imposed. Thus, while presence absence data may alleviate complications with how to interpret counts, the process itself can be highly sensitive to the bioinformatic pipeline used.

Incorporating abundance information with diversity estimates provides one approach to addressing the challenge of uneven sampling. However, the inclusion of relative proportions creates an additional concern in estimating diversity: how to weight the differences in abundances. Hill Numbers are a measure of the effective number of species necessary to produce the observed diversity; as reviewed extensively by Jost (2010) Hill Numbers provide a mechanism to unify measurements of richness, evenness, and diversity. Chao (2014) noted that both incidence-based and relative-abundance measures are sensitive to sampling intensity (ie. sequencing depth) and applied a resampling approach in calculating Hill Number diversity estimates to account for such differences. As shown in Figure 5, we find that diversity estimates for mock community samples are more sensitive to bioinformatic Filtering Method and additional Filtering Parameters with Hill Number q=0 (a measure of richness) than other higher order diversity outcomes. Because the proportions of sequence variants present among denoising pipelines are so similar, the different weighting strategies of dominant species between q=1 and q=2 is nullified. However, the per-sample representative sequences observed and their relative proportions vary considerably more with the cluster-based Vsearch approach; consequently we observe a reduction in diversity as the value of q increases. Compared to the incidence-based measure of diversity with q=0 (Figure 4), a diversity estimate among mock samples with Hill Number q=2 (weighted towards dominant species) suggest that the inclusion of abundances provides a measure of robustness to Filtering Method and Parameter combinations (Figure 6).

A factorial ANOVA was conducted to compare the main effects of Filtering Method, Filtering Parameters, and their interaction on diversity estimates for each Hill Number, with mock samples serving as the replication unit (n=4). Both main effects and their interaction were significant at the p <0.05 level for Hill Numbers q=0 (Table 2) and q=1 (Table 3), while Filtering Method was the only significant main effect for Hill Number q=2 (Table 4) with the interaction of Filtering Method and Parameter insignificant. These data suggest that the Filtering Method is the most important main effect as diversity estimates give greater weight towards the most abundant sequence variants (ie. as q increases). We also used a related nonparametric Kruskal-Wallis test and confirmed diversity estimates were also significant for each Hill Number tested:  q=0 (H(8) = 31.35, p = 0), q = 1 (H(8) = 29.15, p = 0), and q = 2 (H(8) = 31.92, p = 0). A post hoc Dunn’s Test was performed for pairwise combinations of Filtering Method and Parameter, per Hill Number. For q=0 (Table 5) most Benjamini-Hochberg adjusted significance values were greater than p = 0.05, with the only significant pairwise comparisons associating with a Vsearch Filtering Method. A similar effect was observed for q=1 (Table 6) and q=2 (Table 7), with Vsearch Filtering Method paired with a denoising approach being statistically significantly different. These data support our observation that the denoising approaches produce similar diversity estimates across a range of Hill Numbers, but differ from the same estimates produced by the clustering of Vsearch.

In parsing the effects of Filtering Method and Parameters for guano data we added two additional components not used in the the mock community analyses: first, because there were hundreds of samples from each sequencing run, a “Library” term (which sequencing run a sample was derived) was added as another main effect in the model. Second, the variation in per-sample sequence counts was far greater among guano samples, ranging from less than ten sequences to over one million (depending on Filtering Method and Parameters used). Differences in sampling depth are known to influence diversity metrics among high throughput datasets in microbial analyses (Rodriguez-R and Konstantinidis 2014), thus in addition to evaluating diversity estimates for distinct Hill Numbers q=0, 1, or 2, we also investigated the impact of rarefying - randomly subsampling data without replacement - as a means to reduce the impact of variation in sampling depth. While the statistical inadmissibility of such an approach with high throughput data has been questioned (McMurdie and Holmes 2014), we chose this method because of its widespread use, and because alternative normalization techniques have outcomes that are likely to be context dependent (Weiss et al. 2017). Our motivation in comparing unrarefied to rarefied data is to highlight that further normalization is an additional bioinformatic consideration that can impact diet analyses like our other bioinformatic considerations.

As with our mock data, the guano samples demonstrate that incidence-based diversity estimates are higher than estimates using abundances (Figure 7). Similarly, guano samples processed with a clustering Filtering Method generated higher per sample diversity estimate for Hill Number q=0 and were more sensitive to Filtering Parameters than either denoising approach. Incorporating abundance information reduces differences in diversity estimates among the bioinformatic approaches applied to the guano dataset also. Notably, we chose a sampling depth of 5000 reads per sample when rarefying to match one of the two criteria used in the “Standard” Filtering Parameter. Thus, both filtered or rarefied data can increase the per-sample diversity relative to the unrarefied, “basic” filtered data because they each function by dropping samples that contain few reads; the action effectively removes low abundance samples, chopping off the left tail of the distribution of per-sample sequence variants. Rarefying data is most impactful at reducing diversity estimates for the observed sequence variants (Hill Number q=0) among the clustered Vsearch processed data because it contains more low-abundant rare sequences compared to denoised datasets. The same statistical tests applied for our mock dataset were performed for the guano samples, with the exception of including Library the sample was associated with as an effect in the model. For unrarefied data, the Filtering Method, Filtering Parameters, and Library main effects, as well as all interactions, were significant for both Hill Numbers q=0 (Table 8) and q=1 (Table 9), while the three-way interaction was the only non significant term for q=2 (Table 10). Though each main effect was significant across all Hill Numbers for unrarefied data, there was a clear trend in the relative effects of each factor: Filtering Method had the greatest effect for Hill Number q=0 yet least effect for q=2, while Filtering Parameter and library main effects increased with higher Hill Number values. Among rarefied data, each main effect was significant for Hill Numbers q=0 (Table 11), q=1 (Table 12), and q=2 (Table 13), though the two-way interaction of Filtering Method and Filtering Parameter as well as the three-way interaction term of all main effects were not significant for q=1 and q=2. We observed a distinct yet consistent trend among rarefied data: Filtering Parameters - not Method - contributed the greatest effect on diversity estimates for q=0, while the Library main effect was most important for q=2. The number of significant pairwise differences followed a consistent pattern: total pairwise significant differences decreased for datasets that increasingly valued abundance information, or, data that was rarefied (Figures 8-10). In addition, the total number of significant differences was always greatest for Vsearch paired comparisons, though this difference diminished with increasing Hill Number. These guano data suggest that Filtering Method is most impactful when data is not further filtered. Denoised datasets are least susceptible to further Filtering Parameters and relatively unaffected by rarefying, while Vsearch-clustered diversity estimates for Hill Number q=0 are most sensitive to supplemental filtering. Sequencing sample depths are an important consideration for incidence-based estimates of diversity, yet we do not find this effect as impactful for abundance estimates. Likewise, rarefying can function to account for sampling differences, but the utility of this normalization approach is associated directly with the Filtering Method used: helpful with clustered data, but of little consequence and possibly harmful with denoised data.

We applied the same filtering considerations to estimates of intra-sample community composition for our mock samples. Distances were estimated using an incidence-based measure (Dice-Sorensen (referred to as “Dice”)), and two quantitative metrics (Bray-Curtis (“Bray”) and Morisita-Horn (“Morisita”)). While Bray-Curtis is an oft used beta diversity measure, it may not be best suited to the highly variable sampling depths obtained in high throughput amplicon experiments because “observed absolute abundance for any species depends on the sampling fraction (the ratio of sample size to the total number of individuals in the assemblage), so this index becomes meaningless and performs erratically when the sampling fraction is unequal in the two assemblages” Jost (2011). The Morisita-Horn index, however, weights dominant species and is invariant to sampling intensity, offering a different quantitative perspective of community composition from the Bray index. The unique characteristics of each distance measure are apparent in our distance estimates of unrarefied and rarefied samples, processed with distinct Filtering Methods and Parameters (Figure 11). Incidence-based measures are most variable depending on Filtering Method, with the cluster-based Vsearch method being the most sensitive to additional Filtering Parameters. The Bray index is insensitive to Filtering Parameters applied for mock data because the expected mock sequence variants are highly abundant relative to the non mock variants; nevertheless, the differences in sequence depth among these same mock sequences leads to differences in distance estimates for the unrarefied data, while rarefying any Filtering Method dataset uniformly eliminates these differences. Morisita distance estimates vary for Vsearch datasets because of slightly different collections of mock sequence variant, however the denoising methods contained all expected sequence variants thus the distance estimates are similar between rarefied and unrarefied data. As with estimates of inter-sample diversity, we find that denoising methods are less sensitive to variation in Filtering Parameters and produce similar estimates of intra-sample community composition. Interestingly the distance estimates between incidence-based or abundance-based measures depended on the metric, and was influenced by differences in library sizes: even among denoised data that contained almost identical community membership, the total sequencing throughput per Library varied substantially, causing the distances to appear larger in some Bray estimates than Dice. Alternatives normalization strategies other than rarefying are growing in scope and context for questions of differential abundance (Mandal et al. 2015; Paulson et al. 2013) and species diversity (Willis and Bunge 2015), yet the outcomes of these processes are not strictly solutions to a problem created by choosing an inappropriate distance measure.

Summary:
What the hell do I write now?
Methods
Mock samples
Mock community samples were provided by Michelle Jusino and Dan Lindner, and constructed as described by Jusino (2019). In brief, DNA extracted from voucher arthropod specimen was amplified using Jusino’s novel ANML primers; PCR products were cloned into plasmid vectors and Sanger sequenced. This mock community consists of 24 representative COI sequences derived from 23 taxa; one of the taxa (Harmonia axyridis) generated two distinct COI amplicons. The mock community used in this project consists of equimolar concentrations of plasmids, not post-plasmid PCR product. Taxa identities were assigned by both a trained entomologist’s visual confirmation and confirmed by manually aligning sequences to NCBI nt database. Sequence and taxa identities are provided in the ‘CFMR_insect_mock4_wtax.fasta file’ at the Github repo for this project (github.com/devonorourke/tidybug). A single tube containing the mock community sample was used to generate COI amplicons using techniques described below.

Site selection and sample collection
Guano was sampled passively by both researchers and citizen scientists as part of a broader collection effort spanning April through October of 2015 and 2016 throughout multiples sites in the United States including New Hampshire, Massachusetts, Vermont, Maine, Indiana, Kentucky, and Virginia. However, the vast majority of guano samples selected for this report (1,675 of 1,790) were collected in sites specific to New Hampshire. Prospective sites were identified through prior participation in summer maternity roost counts at the volunteers sites. Collection materials were provided and shipped to each volunteer as a kit and included alcohol wipes, forceps, 0.31 mil plastic sheets, collection boxes, and collection tubes filled with 1 mL storage buffer (3.5M ammonium sulfate, 16.7 mM sodium citrate, 13.3 mM EDTA, pH 5.2). Volunteers were provided with instructions to lay a sheet of plastic beneath the location with the greatest amount of fresh droppings; sampling started within the first 6 days, with up to 10 individual pellets being collected each week (ie. one collection tube per pellet). A new sheet of plastic was used each week, and volunteers were instructed to clean forceps between each week of sampling. Samples were shipped back to our lab and stored at -80 °C until DNA extraction commenced.

Laboratory work
Guano samples were thawed and transferred to individual wells of a 96-well plate and extracted using the Qiagen DNEasy PowerSoil Kit (Cat No. 12955-4, Qiagen, Hilden, Germany) following manufacturer guidelines. Samples were eluted in with 60 µL of buffer. Extraction blanks were included for each plate.
We used a dual indexed primer pair inspired by Kozich, Westcott, Baxter, Highlander, and Schloss (2013). This design incorporates both the necessary generic elements of Illumina adapters while allowing for customized barcodes and COI-targeted primer sequences. The COI-specific region of primers match that previously described by Jusino et al. (2019), resulting in primer pairs (ANMLxf:5’-AATGATACGGCGACCACCGAGATCTACAC<i5>TATGGTAATTCGGGTCAACAAATCATAAAGATATTGG-3’) and (ANMLxr:5’-CAAGCAGAAGACGGCATACGAGAT<i7>AGTCAGTCAGCCGGWACTAATCAATTTCCAAATCC-3’), where i5 and i7 represent a unique 8bp barcode. Lists for all possible primer pairs with barcodes are listed in the metadata directory of the Github repo for this project (https://github.com/devonorourke/tidybug/blob/master/data/metadata/primerpairs.txt). 25 µL reactions were performed with 10 µL of extracted DNA, 1 µL each of 10 mM forward and reverse primer pairs, and 13 µL of AccuStart II PCR SuperMix (Cat No. 95137-04K, Quanta BioSciences, Gaithersburgh, MD, USA). Mock community samples were amplified using a distinct primer pair that was not used on any guano samples for any libraries in any study; further, mock samples were amplified in a separate reaction from guano samples to avoid any potential cross contamination. For the mock samples, 1 µL of template DNA with 9 µL of nuclease free water was used in lieu of 10 µL of guano extract. Reaction conditions consisted of: an initial denaturation step at 95 °C for 2 minutes; 30 cycles of denaturation at 95 °C for 20 seconds, annealing at 50 °C for 15 seconds, and extension at 72 °C for 60 seconds; and a final extension at 72 °C for 10 minutes. PCR products were quantified using a PicoGreen assay (Cat No. P7589, Invitrogen, Carlsbad, CA, USA) and Tecan plate reader with excitation and emission wavelengths of 480 nm and 520 nm, respectively (Tecan Group Ltd., Männedorf, Switzerland). Samples were pooled in approximately equimolar ratios; because there were hundreds of samples pooled in a single library, the exact expected equimolar volumes were rounded to the nearest bin (bin sizes set at 0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10, 15, or 20 µL). Extraction blanks or guano samples with detectable DNA that exceeded the maximum pool bin volume were included at a fixed volume of 20 µL. The initial pool volume was reduced with a vacuum concentrator to approximately 2 mL, and cleaned with a QIAquick PCR purification kit (Cat No. 28104, Qiagen, Hilden, Germany); libraries were eluted in 30 µL EB buffer. Libraries were quantified with a Qubit High Sensitivity assay (Cat No. Q32854) and fragment sizes were analyzed using TapeStation D1000 ScreenTape (Agilent Technologies, Santa Clara, CA, USA). Libraries were submitted to Northern Arizona University and sequenced using an Illumina MiSeq platform (Illumina Inc., San Diego, CA, USA) using v3 chemistry with 600 cycles of 2x300 bp paired-end read lengths. Raw sequence reads available at NCBI BioProject PRJNA518082 (https://www.ncbi.nlm.nih.gov/bioproject/PRJNA518082).

Bioinformatics
Complete bioinformatic details are described at the Github repo (github.com/devonorourke/tidybug). All scripts are available at tidybug/scripts, while a single document detailing QIIME processing is available at tidybug/docs/sequence_filtering.md.

Data Processing with QIIME
We imported raw sequence reads into a QIIME2 environment (Bolyen et al. 2018) and trimmed unpaired reads with Cutadapt (Martin 2011). Trimmed reads were then filtered with one of three pipelines: Vsearch (Rognes et al. 2016), DADA2 (Callahan et al. 2016), or Deblur (Amir et al. 2017). We chose to process data on individual libraries rather than concatenating all data together because denoising programs build error models on either a per-sample or per-library basis. Bat-associated COI sequences were identified from filtered reads and removed, then representative sequence (fasta-like) files and frequency tables of sequence counts (OTU table-like) were merged for all libraries. These data were exported into an R environment for further processing (see below).

Mock community samples were included with bat guano amplicon samples for data filtering through the respective pipelines of vsearch, dada2, and deblur, as we expect that the per-sample error rate is similar for mock and guano samples. Mock sequence information was subset from the larger library following the filtering processes described above and aligned to the expected mock representative sequences to determine what ASVs were exact matches (100% identity), partial matches (97 - 99.9% identity), or misses (< 97% identity). Complete details are available in the `tidybug/docs/sequence_filtering.md` document. The maximum count observed among “miss” sequence variants, per mock sample (ie. per library) were what defined the “extra” filtering integer value; note that this value is calculated on a per-library and per-filtering method (vsearch, dada2, deblur) basis.

Data Processing with R
Combined Filtering Method datasets from QIIME2 were transformed in R (R Core Team 2018) version 3.5.1 by importing with the QIIME2R package (Bisanz 2018) and processed with Tidyverse (Wickham 2017), Reshape2 (Wickham 2007), Phyloseq (McMurdie and Holmes 2013), and Vegan (Oksanen et al. 2018) packages. To explore the potential effects of additional filtering parameters a “standard” filter required (1) dropping any sequence variant observed in just one sample across the entire dataset, and (2) retaining only samples with >= 5000 total filtered reads. This filter was chosen as it is commonly used among bat diet studies. An “extra” filter incorporated the “standard” filters, and subtracted a single, fixed integer from each element of the feature table - this serves to remove sequence variants observed with very few read counts. The value is obtained on a per-library basis and is defined as the maximum count value observed of an unexpected sequence variant in the (library-specific) mock sample. While this is by no means a perfect approach, such a minimum-read threshold is often advocated among methods papers in some form. However, rarely is the derivation of this specific value is ever discussed or benchmarked. We opted for the maximum count value as it is more conservative than finding a mean or median value of unexpected sequence variants.

Figures and Statistical tests with R
Following all filtering steps, we assessed diversity estimates using Vegan (Oksanen et al. 2018) for each combination of Filtering Methods (vsearch, dada2, or deblur) and Parameters (none, standard, extended). Parametric statistical tests were performed with base R “stats” function ‘aov’, and nonparametric pairwise comparisons were performed with the Matrix (Bates and Maechler 2018), FSA (Ogle et al. 2018), and Dunn.test packages (Dinno 2017). We relied on a series of additional R packages to create the figures used in this manuscript including cowplot (Wilke ), ggpubr (Kassambara 2018), ggrepel (Slowikowski 2018), ggridges (Wilke 2018), stringi (Gagolewski 2019), scales (Wickham 2018), and viridis (Garnier 2018).
