StartMonthstring <- c("April","April","April","April","April","May","May","May","May","June","June","June","June","July","July","July","July","July","August","August","August","August","September","September","September","September","October","October","October","October", "ncontrol", "mock")
tmp <- data.frame(WOYstring, StartMonthstring)
colnames(tmp) <- c("WOY", "MonthStart")
meta <- merge(meta, tmp, all.x=TRUE)
meta$MonthStart <- as.character(meta$MonthStart)
meta[is.na(meta)] <- "ncontrol"
## merge data:
df <- merge(df, meta, by='SeqID', all.x=TRUE)
colnames(df)[1] <- "SampleID"
rm(meta, meta_names, studytargets, tmp, StartMonthstring, WOYstring)
## relabel a few elements within Mock data
df$WOY[df$SampleType=='mock'] <- "mock"
df$Site[df$SampleType=='mock'] <- "mock"
df$Date[df$SampleType=='mock'] <- "mock"
df$MonthStart[df$SampleType=='mock'] <- "mock"
df$DNAplate[df$SampleType=='mock'] <- "mock"
## Rename the Site and WOY functions for the 'ncontrol' values so that they reflect the..
## ..per-DNAplate where they came from... it's the best way I can think of to group negative control samples
tmp <- df %>% filter(SampleType=='ncontrol')
df$WOY[df$SampleType=='ncontrol'] <- paste("ncontrol", tmp$DNAplate, sep = ".")
df$Site[df$SampleType=='ncontrol'] <- paste("ncontrol", tmp$DNAplate, sep = ".")
rm(tmp)
## We're going to create filtered datasets that require two things:
#1) a sample must have at least 5500 filtered reads
#2) an OTU/ASV must be present in at least 2 samples of the filtered samples
#3) a sample must have >= 5500 reads following the removal of any singleton OTU/ASVs
vs.pass <- df %>% filter(Method=="vsearch") %>% group_by(SampleID) %>% summarize(ReadCounts=sum(Reads)) %>% filter(ReadCounts >=5500)
da.pass <- df %>% filter(Method=="dada2") %>% group_by(SampleID) %>% summarize(ReadCounts=sum(Reads)) %>% filter(ReadCounts >=5500)
db.pass <- df %>% filter(Method=="deblur") %>% group_by(SampleID) %>% summarize(ReadCounts=sum(Reads)) %>% filter(ReadCounts >=5500)
vs.passOTU <- df %>% filter(Method=="vsearch" & SampleID %in% vs.pass$SampleID) %>% group_by(HashID) %>% summarise(OTUcounts=n()) %>% filter(OTUcounts > 1)
da.passOTU <- df %>% filter(Method=="dada2" & SampleID %in% da.pass$SampleID) %>% group_by(HashID) %>% summarise(OTUcounts=n()) %>% filter(OTUcounts > 1)
db.passOTU <- df %>% filter(Method=="deblur" & SampleID %in% db.pass$SampleID) %>% group_by(HashID) %>% summarise(OTUcounts=n()) %>% filter(OTUcounts > 1)
vs.filt.df <- df %>% filter(Method=="vsearch" & SampleID %in% vs.pass$SampleID & HashID %in% vs.passOTU$HashID)
da.filt.df <- df %>% filter(Method=="dada2" & SampleID %in% da.pass$SampleID & HashID %in% da.passOTU$HashID)
db.filt.df <- df %>% filter(Method=="deblur" & SampleID %in% db.pass$SampleID & HashID %in% db.passOTU$HashID)
vs.SamplePass_2 <- vs.filt.df %>% group_by(SampleID) %>% summarise(ReadSums=sum(Reads)) %>% filter(ReadSums >= 5500)
da.SamplePass_2 <- da.filt.df %>% group_by(SampleID) %>% summarise(ReadSums=sum(Reads)) %>% filter(ReadSums >= 5500)
db.SamplePass_2 <- db.filt.df %>% group_by(SampleID) %>% summarise(ReadSums=sum(Reads)) %>% filter(ReadSums >= 5500)
vs.filt.df <- vs.filt.df %>% filter(SampleID %in% vs.SamplePass_2$SampleID)
da.filt.df <- da.filt.df %>% filter(SampleID %in% da.SamplePass_2$SampleID)
db.filt.df <- db.filt.df %>% filter(SampleID %in% db.SamplePass_2$SampleID)
filt.df <- rbind(vs.filt.df, da.filt.df, db.filt.df)
#rm(vs.filt.df, da.filt.df, db.filt.df)
## Amd we'll create the select Fox State dataset by subsetting from the already filtered datasets above
## Subset just the site we're going to investigate, retaining negative control samples in associated DNAextraction plates..
## Subset just the two libraries of interest:
libraries <- c("libA", "libD")
tmp.df <- df %>% filter(Library %in% libraries)
select1 <- c("FOX")
dat.tmp1 <- tmp.df %>% filter(Site %in% select1)
select2 <- dat.tmp1 %>% distinct(DNAplate)
select2 <- as.character(select2$DNAplate)
dat.tmp2 <- tmp.df %>% filter(SampleType=="ncontrol" & DNAplate %in% select2)
possibleNegs <- dat.tmp2$SampleID
vs.foxnegs <- intersect(vs.filt.df$SampleID, possibleNegs)
da.foxnegs <- intersect(da.filt.df$SampleID, possibleNegs)
db.foxnegs <- intersect(db.filt.df$SampleID, possibleNegs)
vs.foxSamps <- vs.filt.df %>% filter(Site=="FOX")
vs.foxSamps <- as.character(unique(vs.foxSamps$SampleID))
da.foxSamps <- da.filt.df %>% filter(Site=="FOX")
da.foxSamps <- as.character(unique(da.foxSamps$SampleID))
db.foxSamps <- db.filt.df %>% filter(Site=="FOX")
db.foxSamps <- as.character(unique(db.foxSamps$SampleID))
vs.FoxAllSamps <- c(vs.foxSamps, vs.foxnegs)
da.FoxAllSamps <- c(da.foxSamps, da.foxnegs)
db.FoxAllSamps <- c(db.foxSamps, db.foxnegs)
libraries <- c("libA", "libD")
vs.fox.df <- vs.filt.df %>% filter(Library %in% libraries & SampleID %in% vs.FoxAllSamps)
da.fox.df <- da.filt.df %>% filter(Library %in% libraries & SampleID %in% da.FoxAllSamps)
db.fox.df <- db.filt.df %>% filter(Library %in% libraries & SampleID %in% db.FoxAllSamps)
fox.filt.df <- rbind(vs.fox.df, da.fox.df, db.fox.df)
passFoxFilt <- fox.filt.df %>%
group_by(SampleID, Site, WOY, Method) %>%
summarise(Counts=n()) %>%
select(-Counts) %>%
group_by(Site, WOY, Method) %>%
summarise(SampleCounts=n()) %>%
filter(SampleCounts > 1)
## note that the one remaining negative control in this sample no longer satisifes ##2. above (it exists in dada2 and vsearch, but not deblur)
## we'll remove that from the final filtered dataset as well as other WOYs which fail this requirement (like WOY==16)
fox.filt.df <- fox.filt.df %>% filter(MonthStart != "ncontrol") %>% filter(WOY %in% passFoxFilt$WOY)
fox.filt.df %>%
group_by(SampleID, Site, WOY, Method) %>%
summarise(Counts=n()) %>%
select(-Counts) %>%
group_by(Site, WOY, Method) %>%
summarise(SampleCounts=n())
fox.filt.df %>%
group_by(SampleID, Site, WOY, Method) %>%
summarise(Counts=n())
## note that the one remaining negative control in this sample no longer satisifes ##2. above (it exists in dada2 and vsearch, but not deblur)
## we'll remove that from the final filtered dataset as well as other WOYs which fail this requirement (like WOY==16)
fox.filt.df <- fox.filt.df %>% filter(MonthStart != "ncontrol") %>% filter(WOY %in% passFoxFilt$WOY)
View(fox.filt.df)
## save a list of the SampleIDs for each filtering method; used in Phyloseq work
vs.filt.names <- fox.filt.df %>% filter(Method=="vsearch")
## save a list of the SampleIDs for each filtering method; used in Phyloseq work
vs.filt.names <- fox.filt.df %>% filter(Method=="vsearch") %>% distinct(SampleID)
vs.pass <- df %>% filter(Method=="vsearch") %>% group_by(SampleID) %>% summarize(ReadCounts=sum(Reads)) %>% filter(ReadCounts >=5000)
da.pass <- df %>% filter(Method=="dada2") %>% group_by(SampleID) %>% summarize(ReadCounts=sum(Reads)) %>% filter(ReadCounts >=5000)
db.pass <- df %>% filter(Method=="deblur") %>% group_by(SampleID) %>% summarize(ReadCounts=sum(Reads)) %>% filter(ReadCounts >=5000)
vs.passOTU <- df %>% filter(Method=="vsearch" & SampleID %in% vs.pass$SampleID) %>% group_by(HashID) %>% summarise(OTUcounts=n()) %>% filter(OTUcounts > 1)
da.passOTU <- df %>% filter(Method=="dada2" & SampleID %in% da.pass$SampleID) %>% group_by(HashID) %>% summarise(OTUcounts=n()) %>% filter(OTUcounts > 1)
db.passOTU <- df %>% filter(Method=="deblur" & SampleID %in% db.pass$SampleID) %>% group_by(HashID) %>% summarise(OTUcounts=n()) %>% filter(OTUcounts > 1)
vs.filt.df <- df %>% filter(Method=="vsearch" & SampleID %in% vs.pass$SampleID & HashID %in% vs.passOTU$HashID)
da.filt.df <- df %>% filter(Method=="dada2" & SampleID %in% da.pass$SampleID & HashID %in% da.passOTU$HashID)
db.filt.df <- df %>% filter(Method=="deblur" & SampleID %in% db.pass$SampleID & HashID %in% db.passOTU$HashID)
vs.SamplePass_2 <- vs.filt.df %>% group_by(SampleID) %>% summarise(ReadSums=sum(Reads)) %>% filter(ReadSums >= 5000)
da.SamplePass_2 <- da.filt.df %>% group_by(SampleID) %>% summarise(ReadSums=sum(Reads)) %>% filter(ReadSums >= 5000)
db.SamplePass_2 <- db.filt.df %>% group_by(SampleID) %>% summarise(ReadSums=sum(Reads)) %>% filter(ReadSums >= 5000)
vs.filt.df <- vs.filt.df %>% filter(SampleID %in% vs.SamplePass_2$SampleID)
da.filt.df <- da.filt.df %>% filter(SampleID %in% da.SamplePass_2$SampleID)
db.filt.df <- db.filt.df %>% filter(SampleID %in% db.SamplePass_2$SampleID)
filt.df <- rbind(vs.filt.df, da.filt.df, db.filt.df)
## We want to create the selected Fox State dataset by subsetting from the already filtered datasets above
## We can also include any possible negative control samples in associated DNAextraction plates within that Fox State dataset..
## Subset just the two libraries of interest (Fox State data only generated from 2 of 4 libraries analyzed):
libraries <- c("libA", "libD")
tmp.df <- df %>% filter(Library %in% libraries)
select1 <- c("FOX")
dat.tmp1 <- tmp.df %>% filter(Site %in% select1)
select2 <- dat.tmp1 %>% distinct(DNAplate)
select2 <- as.character(select2$DNAplate)
dat.tmp2 <- tmp.df %>% filter(SampleType=="ncontrol" & DNAplate %in% select2)
possibleNegs <- dat.tmp2$SampleID
vs.foxnegs <- intersect(vs.filt.df$SampleID, possibleNegs)
da.foxnegs <- intersect(da.filt.df$SampleID, possibleNegs)
db.foxnegs <- intersect(db.filt.df$SampleID, possibleNegs)
vs.foxSamps <- vs.filt.df %>% filter(Site=="FOX")
vs.foxSamps <- as.character(unique(vs.foxSamps$SampleID))
da.foxSamps <- da.filt.df %>% filter(Site=="FOX")
da.foxSamps <- as.character(unique(da.foxSamps$SampleID))
db.foxSamps <- db.filt.df %>% filter(Site=="FOX")
db.foxSamps <- as.character(unique(db.foxSamps$SampleID))
vs.FoxAllSamps <- c(vs.foxSamps, vs.foxnegs)
da.FoxAllSamps <- c(da.foxSamps, da.foxnegs)
db.FoxAllSamps <- c(db.foxSamps, db.foxnegs)
libraries <- c("libA", "libD")
vs.fox.df <- vs.filt.df %>% filter(Library %in% libraries & SampleID %in% vs.FoxAllSamps)
da.fox.df <- da.filt.df %>% filter(Library %in% libraries & SampleID %in% da.FoxAllSamps)
db.fox.df <- db.filt.df %>% filter(Library %in% libraries & SampleID %in% db.FoxAllSamps)
fox.filt.df <- rbind(vs.fox.df, da.fox.df, db.fox.df)
passFoxFilt <- fox.filt.df %>%
group_by(SampleID, Site, WOY, Method) %>%
summarise(Counts=n()) %>%
select(-Counts) %>%
group_by(Site, WOY, Method) %>%
summarise(SampleCounts=n()) %>%
filter(SampleCounts > 1)
View(passFoxFilt)
## note that the one remaining negative control group in this set exists in dada2 and vsearch, but not deblur..
## these two samples were ignored for sake of comparisons between filtering strategies
## we'll remove that from the final filtered dataset as well as other WOYs which fail this requirement (like WOY==16)
fox.filt.df <- fox.filt.df %>% filter(MonthStart != "ncontrol") %>% filter(WOY %in% passFoxFilt$WOY)
## save a list of the SampleIDs for each filtering method; used in Phyloseq work
vs.filt.names <- fox.filt.df %>% filter(Method=="vsearch") %>% distinct(SampleID)
## save a list of the SampleIDs for each filtering method; used in Phyloseq work
vs.Fox.names <- fox.filt.df %>% filter(Method=="vsearch") %>% distinct(SampleID)
View(vs.Fox.names)
da.Fox.names <- fox.filt.df %>% filter(Method=="dada2") %>% distinct(SampleID)
db.Fox.names <- fox.filt.df %>% filter(Method=="deblur") %>% distinct(SampleID)
View(db.Fox.names)
write.csv(vs.Fox.names, file="~/Documents/dissertation/methods_paper2/data/", quote = FALSE, row.names = FALSE)
write.csv(vs.Fox.names, file="~/Documents/dissertation/methods_paper2/data/vs.foxnames.csv", quote = FALSE, row.names = FALSE)
write.csv(da.Fox.names, file="~/Documents/dissertation/methods_paper2/data/da.foxnames.csv", quote = FALSE, row.names = FALSE)
write.csv(db.Fox.names, file="~/Documents/dissertation/methods_paper2/data/db.foxnames.csv", quote = FALSE, row.names = FALSE)
rm(da.filt.df, da.fox.df, da.pass, da.passOTU)
rm(dat.tmp1, dat.tmp2)
rm(da.SamplePass_2)
rm(db.filt.df, db.fox.df, db.pass, db.passOTU, db.SamplePass_2)
rm(df, filt.df, fox.filt.df, passFoxFilt, vs.filt.df)
rm(fs.fox.df, vs.pass, vs.passOTU)
rm(vs.filt.names, vs.fox.df)
rm(tmp.df)
rm(vs.SamplePass_2)
rm(da.FoxAllSamps, da.foxnegs, da.foxSamps, da.foxnegs, db.foxnegs, db.foxSamps)
rm(possibleNegs, select1, select2, outdir)
rm(vs.FoxAllSamps, vs.foxnegs)
rm(vs.foxSamps, tofactor, libraries)
rm(db.FoxAllSamps)
## subset physeq object to select the selected Fox State Forest samples
## import fox sample IDs:
vs.foxnames <- read_csv('https://github.com/devonorourke/pzero/raw/master/data/vs.foxnames.csv')
## export OTU table from
vs.basic.min16.fox <- subset_samples(vs.phy.basic.min16, SampleID %in% vs.foxnames$SampleID)
sample_names(vs.basic.min16.fox)
nsamples(vs.basic.min16.fox)
vs.rare.min16.fox <- subset_samples(vs.phy.rare.min16, SampleID %in% vs.foxnames$SampleID)
da.foxnames <- read_csv('https://github.com/devonorourke/pzero/raw/master/data/da.foxnames.csv')
db.foxnames <- read_csv('https://github.com/devonorourke/pzero/raw/master/data/vs.foxnames.csv')
?rngseed
db.phy.norm.min16 = DESeq(db.phy.norm.min16, test="Wald", fitType = "local")
db.tmp.min16 <- transform_sample_counts(db.phy.basic.min16, function(OTU) OTU + 1 )
db.phy.norm.min16 = phyloseq_to_deseq2(db.tmp.min16, ~ Library)
rm(db.tmp.min16)
db.phy.norm.min16 = DESeq(db.phy.norm.min16, test="Wald", fitType = "local")
vs.tmp.min1 <- transform_sample_counts(vs.phy.basic.min1, function(OTU) OTU + 1 ) ## adding pseudo count of +1 to OTU table to avoid transformation error
var2get <- sample_variables(vs.tmp.min1)  ## gathers metadata we'll need to merge back with normalized OTU data
meta.tmp <- get_variable(vs.tmp.min1, var2get)   ## creating metadata phyloseq object to merge with normalized data
row.names(meta.tmp) <- meta.tmp$SampleID    ## add SampleID values to row.names to match!
head(vs.basic.min16.jacc)
class(vs.basic.min16.jacc)
library(tidyverse)
meta <- read_delim('https://raw.githubusercontent.com/devonorourke/pzero/master/data/clean_metadata.txt/clean_metadata.txt', sep="\t")
meta <- read_delim('https://raw.githubusercontent.com/devonorourke/pzero/master/data/clean_metadata.txt/clean_metadata.txt', delim = "\t")
meta <- read_delim('https://github.com/devonorourke/pzero/raw/master/data/clean_metadata.txt', delim = "\t")
p41 <- read.csv("~/Desktop/p41.manifest.file")
p42 <- read.csv("~/Desktop/p42.manifest.file")
p71 <- read.csv("~/Desktop/p71.manifest.file")
p72 <- read.csv("~/Desktop/p72.manifest.file")
pall <- rbind(p41, p42, p71, p72)
pSamples <- pall$sample.id
samplemeta <- intersect(meta$SampleID, pall$sample.id)
View(pall)
View(meta)
samplemeta <- intersect(meta$SeqID, pall$sample.id)
meta2 <- meta %>% filter(SeqID %in% samplemeta)
View(meta2)
meta <- meta %>% filter(SeqID %in% samplemeta)
rm(p41, p42, p71, p72, pSamples, samplemeta)
rm(meta2)
meta$Site <- gsub("control", "ncontrol", meta$Site)
meta$Date <- gsub("control", "ncontrol", meta$Date)
## overwrite new $Date and $WOY columns with lubridate package to ensure we're selecting a consistent WOY
meta$Date <- as.character(lubridate::mdy(meta$Date))
meta$WOY <- as.character(lubridate::isoweek(meta$Date))
meta[is.na(meta)] <- "ncontrol"
meta <- read_delim('https://github.com/devonorourke/pzero/raw/master/data/clean_metadata.txt', delim = "\t")
p41 <- read.csv("~/Desktop/p41.manifest.file")
p42 <- read.csv("~/Desktop/p42.manifest.file")
p71 <- read.csv("~/Desktop/p71.manifest.file")
p72 <- read.csv("~/Desktop/p72.manifest.file")
pall <- rbind(p41, p42, p71, p72)
pSamples <- pall$sample.id
samplemeta <- intersect(meta$SeqID, pall$sample.id)
meta <- meta %>% filter(SeqID %in% samplemeta)
meta$Site <- gsub("control", "ncontrol", meta$Site)
meta$Date <- gsub("control", "ncontrol", meta$Date)
## overwrite new $Date and $WOY columns with lubridate package to ensure we're selecting a consistent WOY
meta$NewDate <- as.character(lubridate::ymd(meta$Date))
## overwrite new $Date and $WOY columns with lubridate package to ensure we're selecting a consistent WOY
meta$NewDate <- as.character(lubridate::mdy(meta$Date))
meta$NewDate[which(meta$SampleType == "ncontrol")] = "2000-01-01"
meta$NewDate[which(meta$Date == "unknown")] = "2000-01-01"
meta$NewDate[which(meta$SampleID == "35A01")] = "2000-01-01"
meta$NewDate[which(meta$SampleType == "mock")] = "2000-01-01"
meta$Library <- gsub("4.1", "libA", meta$SeqBatch)
meta$Library <- gsub("4.2", "libB", meta$SeqBatch)
meta$Library <- gsub("7.1", "libC", meta$SeqBatch)
meta$Library <- gsub("7.2", "libD", meta$SeqBatch)
meta$Library <- meta$SeqBatch
meta$Library <- gsub("4.1", "libA", meta$SeqBatch)
meta$Library <- gsub("4.2", "libB", meta$SeqBatch)
meta$Library <- gsub("7.1", "libC", meta$SeqBatch)
meta$Library <- gsub("7.2", "libD", meta$SeqBatch)
meta$Library <- gsub("4.1", "libA", meta$SeqBatch)
meta$Library <- gsub("4.1", "libA", meta$Library)
meta$Library <- gsub("4.2", "libB", meta$Library)
meta$Library <- gsub("7.1", "libC", meta$Library)
meta$Library <- gsub("7.2", "libD", meta$Library)
newmeta <- meta[,c(5,11,14,23,24)]
View(newmeta)
unique(newmeta$Site)
newmeta$newSite <- gsub("HOP", "Hopkinton, NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park, ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station, VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine, VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane, Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill, Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ncontrol", "", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford, NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook, NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom, NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury, NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum, NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness, NH", newmeta$newSite)
newmeta$newSite <- gsub("CHI", "Chichester, NH", newmeta$newSite)
newmeta$newSite <- gsub("MAS", "Massabesic, NH", newmeta$newSite)
newmeta$newSite <- gsub("FOX", "Fox State Forest, NH", newmeta$newSite)
newmeta$newSite <- gsub("FAR", "Fairfield, ME", newmeta$newSite)
newmeta$newSite <- gsub("MTV", "Mount Vernon, NH", newmeta$newSite)
newmeta$newSite <- gsub("ALS", "Alstead, NH", newmeta$newSite)
newmeta$newSite <- ""
newmeta$newSite <- gsub("HOP", "Hopkinton, NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park, ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station, VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine, VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane, Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill, Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ncontrol", "", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford, NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook, NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom, NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury, NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum, NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness, NH", newmeta$newSite)
newmeta$newSite <- newmeta$Site
newmeta$newSite <- gsub("HOP", "Hopkinton, NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park, ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station, VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine, VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane, Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill, Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ncontrol", "", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford, NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook, NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom, NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury, NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum, NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness, NH", newmeta$newSite)
newmeta$newSite <- gsub("CHI", "Chichester, NH", newmeta$newSite)
newmeta$newSite <- gsub("MAS", "Massabesic, NH", newmeta$newSite)
newmeta$newSite <- gsub("FOX", "Fox State Forest, NH", newmeta$newSite)
newmeta$newSite <- gsub("FAR", "Fairfield, ME", newmeta$newSite)
newmeta$newSite <- gsub("MTV", "Mount Vernon, NH", newmeta$newSite)
newmeta$newSite <- gsub("ALS", "Alstead, NH", newmeta$newSite)
write.csv(newmeta, file="~/Desktop/newmeta.csv", quote=FALSE, row.names = FALSE)
newmeta$newSite <- newmeta$Site
newmeta$newSite <- gsub("HOP", "Hopkinton NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ncontrol", "", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness NH", newmeta$newSite)
newmeta$newSite <- gsub("CHI", "Chichester NH", newmeta$newSite)
newmeta$newSite <- gsub("MAS", "Massabesic NH", newmeta$newSite)
newmeta$newSite <- gsub("FOX", "Fox State Forest NH", newmeta$newSite)
newmeta$newSite <- gsub("FAR", "Fairfield ME", newmeta$newSite)
newmeta$newSite <- gsub("MTV", "Mount Vernon NH", newmeta$newSite)
newmeta$newSite <- gsub("ALS", "Alstead NH", newmeta$newSite)
newmeta$Site <- NULL
write.csv(newmeta, file="~/Desktop/newmeta.csv", quote=FALSE, row.names = FALSE)
newmeta$newSite <- newmeta$Site
newmeta <- meta[,c(5,11,14,23,24)]
newmeta$newSite <- newmeta$Site
newmeta$newSite <- gsub("HOP", "Hopkinton NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness NH", newmeta$newSite)
newmeta$newSite <- gsub("CHI", "Chichester NH", newmeta$newSite)
newmeta$newSite <- gsub("MAS", "Massabesic NH", newmeta$newSite)
newmeta$newSite <- gsub("FOX", "Fox State Forest NH", newmeta$newSite)
newmeta$newSite <- gsub("FAR", "Fairfield ME", newmeta$newSite)
newmeta$newSite <- gsub("MTV", "Mount Vernon NH", newmeta$newSite)
newmeta$newSite <- gsub("ALS", "Alstead NH", newmeta$newSite)
meta$NewDate[which(meta$SampleType == "mock")] = "2000-01-01"
newmeta$newSite[which(newmeta$SampleType == "mock")] = "mock"
newmeta$Site <- NULL
write.csv(newmeta, file="~/Desktop/newmeta.csv", quote=FALSE, row.names = FALSE)
newmeta$bioproject_accession <- ""
newmeta$bioproject_accession <- "SUB5109424"
newmeeta$organism <- "not collected"
newmeta$env_broad_scale <- "not collected"
newmeta$env_local_scale <- "not applicable"
newmeta$organism <- "not collected"
newmeta$env_broad_scale <- "not collected"
newmeta$env_local_scale <- "not applicable"
newmeta$env_medium <- "not applicable"
newmeta$host <- "not collected"
newmeta$lat_lon <- "not applicable"
newmeta$AltDate <- newmeta$NewDate
meta$AltDate[which(newmeta$SampleType == "ncontrol")] = "not applicable"
meta$AltDate[which(newmeta$Date == "unknown")] = "not collected"
meta$AltDate[which(newmeta$SampleType == "ncontrol")] = "not applicable"
meta <- read_delim('https://github.com/devonorourke/pzero/raw/master/data/clean_metadata.txt', delim = "\t")
p41 <- read.csv("~/Desktop/p41.manifest.file")
p42 <- read.csv("~/Desktop/p42.manifest.file")
p71 <- read.csv("~/Desktop/p71.manifest.file")
p72 <- read.csv("~/Desktop/p72.manifest.file")
pall <- rbind(p41, p42, p71, p72)
pSamples <- pall$sample.id
samplemeta <- intersect(meta$SeqID, pall$sample.id)
meta <- meta %>% filter(SeqID %in% samplemeta)
#rm(p41, p42, p71, p72, pSamples, samplemeta)
########
meta$Site <- gsub("control", "ncontrol", meta$Site)
meta$Date <- gsub("control", "ncontrol", meta$Date)
## overwrite new $Date and $WOY columns with lubridate package to ensure we're selecting a consistent WOY
meta$NewDate <- as.character(lubridate::mdy(meta$Date))
## any samples we'd be discarding or are NA are converted to generic date
meta$NewDate[which(meta$SampleType == "ncontrol")] = "2000-01-01"
meta$NewDate[which(meta$Date == "unknown")] = "2000-01-01"
meta$NewDate[which(meta$SampleID == "35A01")] = "2000-01-01"
meta$NewDate[which(meta$SampleType == "mock")] = "2000-01-01"
meta$Library <- meta$SeqBatch
meta$Library <- gsub("4.1", "libA", meta$Library)
meta$Library <- gsub("4.2", "libB", meta$Library)
meta$Library <- gsub("7.1", "libC", meta$Library)
meta$Library <- gsub("7.2", "libD", meta$Library)
newmeta <- meta[,c(5,11,14,23,24)]
newmeta$newSite <- newmeta$Site
newmeta$newSite <- gsub("HOP", "Hopkinton NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness NH", newmeta$newSite)
newmeta$newSite <- gsub("CHI", "Chichester NH", newmeta$newSite)
newmeta$newSite <- gsub("MAS", "Massabesic NH", newmeta$newSite)
newmeta$newSite <- gsub("FOX", "Fox State Forest NH", newmeta$newSite)
newmeta$newSite <- gsub("FAR", "Fairfield ME", newmeta$newSite)
newmeta$newSite <- gsub("MTV", "Mount Vernon NH", newmeta$newSite)
newmeta$newSite <- gsub("ALS", "Alstead NH", newmeta$newSite)
newmeta$newSite[which(newmeta$SampleType == "mock")] = "mock"
newmeta$Site <- NULL
newmeta$AltDate <- newmeta$NewDate
newmeta$AltDate[which(newmeta$SampleType == "ncontrol")] = "not applicable"
newmeta$AltDate[which(newmeta$Date == "unknown")] = "not collected"
newmeta$AltDate[which(newmeta$SampleID == "35A01")] = "not applicable"
newmeta$AltDate[which(newmeta$NewDate == "unknown")] = "not collected"
newmeta$AltDate[which(newmeta$SeqID == "negoro35A01")] = "not applicable"
newmeta$AltDate[which(newmeta$SampleType == "mock")] = "not applicable"
newmeta$AltDate[which(newmeta$newSite == "Canterbury NH" & Library == "libD")] = "not applicable"
newmeta$AltDate[which(newmeta$newSite == "Canterbury NH" & newmeta$Library == "libD")] = "not applicable"
View(newmeta)
newmeta$AltDate[which(newmeta$newSite == "Canterbury NH" & newmeta$Library == "libD" & newmeta$NewDate == "2000-01-01")] = "not applicable"
newmeta$AltDate <- newmeta$NewDate
newmeta$AltDate[which(newmeta$SampleType == "ncontrol")] = "not applicable"
newmeta$AltDate[which(newmeta$NewDate == "unknown")] = "not collected"
newmeta$AltDate[which(newmeta$SeqID == "negoro35A01")] = "not applicable"
newmeta$AltDate[which(newmeta$newSite == "Canterbury NH" & newmeta$Library == "libD" & newmeta$NewDate == "2000-01-01")] = "not applicable"
newmeta$AltDate[which(newmeta$SampleType == "mock")] = "not applicable"
meta <- read_delim('https://github.com/devonorourke/pzero/raw/master/data/clean_metadata.txt', delim = "\t")
p41 <- read.csv("~/Desktop/p41.manifest.file")
p42 <- read.csv("~/Desktop/p42.manifest.file")
p71 <- read.csv("~/Desktop/p71.manifest.file")
p72 <- read.csv("~/Desktop/p72.manifest.file")
pall <- rbind(p41, p42, p71, p72)
pSamples <- pall$sample.id
samplemeta <- intersect(meta$SeqID, pall$sample.id)
meta <- meta %>% filter(SeqID %in% samplemeta)
#rm(p41, p42, p71, p72, pSamples, samplemeta)
########
meta$Site <- gsub("control", "ncontrol", meta$Site)
meta$Date <- gsub("control", "ncontrol", meta$Date)
## overwrite new $Date and $WOY columns with lubridate package to ensure we're selecting a consistent WOY
meta$NewDate <- as.character(lubridate::mdy(meta$Date))
## any samples we'd be discarding or are NA are converted to generic date
meta$NewDate[which(meta$SampleType == "ncontrol")] = "2000-01-01"
meta$NewDate[which(meta$Date == "unknown")] = "2000-01-01"
meta$NewDate[which(meta$SampleID == "35A01")] = "2000-01-01"
meta$NewDate[which(meta$SampleType == "mock")] = "2000-01-01"
meta$Library <- meta$SeqBatch
meta$Library <- gsub("4.1", "libA", meta$Library)
meta$Library <- gsub("4.2", "libB", meta$Library)
meta$Library <- gsub("7.1", "libC", meta$Library)
meta$Library <- gsub("7.2", "libD", meta$Library)
newmeta <- meta[,c(5,11,14,23,24)]
newmeta$newSite <- newmeta$Site
newmeta$newSite <- gsub("HOP", "Hopkinton NH", newmeta$newSite)
newmeta$newSite <- gsub("ACA", "Acadia National Park ME", newmeta$newSite)
newmeta$newSite <- gsub("YRK", "Yorktown Naval Weapons Station VA", newmeta$newSite)
newmeta$newSite <- gsub("ELY", "Ely Mine VT", newmeta$newSite)
newmeta$newSite <- gsub("BRN", "Brown Lane Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("MAP", "Maple Hill Hollis NH", newmeta$newSite)
newmeta$newSite <- gsub("ROL", "Rollinsford NH", newmeta$newSite)
newmeta$newSite <- gsub("PEN", "Penacook NH", newmeta$newSite)
newmeta$newSite <- gsub("EPS", "Epsom NH", newmeta$newSite)
newmeta$newSite <- gsub("CNB", "Canterbury NH", newmeta$newSite)
newmeta$newSite <- gsub("GIL", "Gilsum NH", newmeta$newSite)
newmeta$newSite <- gsub("HOL", "Holderness NH", newmeta$newSite)
newmeta$newSite <- gsub("CHI", "Chichester NH", newmeta$newSite)
newmeta$newSite <- gsub("MAS", "Massabesic NH", newmeta$newSite)
newmeta$newSite <- gsub("FOX", "Fox State Forest NH", newmeta$newSite)
newmeta$newSite <- gsub("FAR", "Fairfield ME", newmeta$newSite)
newmeta$newSite <- gsub("MTV", "Mount Vernon NH", newmeta$newSite)
newmeta$newSite <- gsub("ALS", "Alstead NH", newmeta$newSite)
newmeta$newSite[which(newmeta$SampleType == "mock")] = "mock"
newmeta$Site <- NULL
newmeta$bioproject_accession <- "SUB5109424"
newmeta$organism <- "not collected"
newmeta$env_broad_scale <- "not collected"
newmeta$env_local_scale <- "not applicable"
newmeta$env_medium <- "not applicable"
newmeta$host <- "not collected"
newmeta$lat_lon <- "not applicable"
newmeta$AltDate <- newmeta$NewDate
newmeta$AltDate[which(newmeta$SampleType == "ncontrol")] = "not applicable"
newmeta$AltDate[which(newmeta$NewDate == "unknown")] = "not collected"
newmeta$AltDate[which(newmeta$SampleType == "mock")] = "not applicable"
newmeta$AltDate[which(newmeta$newSite == "Canterbury NH" & newmeta$Library == "libD" & newmeta$NewDate == "2000-01-01")] = "not collected"
write.csv(newmeta, file="~/Desktop/newmeta.csv", quote=FALSE, row.names = FALSE)
setwd("~/Repos/tidybug/data/")
list.files()
getwd()
setwd("~/Repos/tidybug/data/metadata/")
download.file("https://github.com/devonorourke/tidybug/raw/master/data/metadata/metadata.tsv", "metadata.tsv")
## import metadata, combine with df object:
download.file("https://github.com/devonorourke/pzero/raw/master/data/metadata.tsv", "metadata.tsv")
## import hashID lists and resolve sha1 vs MD5-hash'd strings in the headers
download.file("https://github.com/devonorourke/pzero/raw/master/data/allheaders.txt.gz", "allheaders.txt.gz")
